{
    "input_data_types": "We transform the fp32 input data to int8 data.",
    "retraining": "We donâ€™t retrain the model weight.",
    "starting_weights_filename": "The original weight filename: https://zenodo.org/record/3401714/files/ssd_mobilenet_v1_quant_ft_no_zero_point_frozen_inference_graph.pb and the transformed int8 weight named init_net_int8_euler.pb",
    "weight_data_types": "We transform the original fp32 weight to int8 weight.",
    "weight_transformations": "We transform the weight from fp32 datatype in onnx file to int8 datatype in pb file."
}
